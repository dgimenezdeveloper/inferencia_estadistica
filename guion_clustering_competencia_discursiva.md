# Gui√≥n para Presentaci√≥n Oral - Competencia Discursiva
## An√°lisis de Clustering para Segmentaci√≥n de Empleados en Riesgo de Rotaci√≥n

---

**Materia:** Inferencia Estad√≠stica y Reconocimiento de Patrones  
**Universidad:** Universidad Nacional Guillermo Brown  
**Aplicaci√≥n Web:** https://inferencia-estadistica-unab.streamlit.app/  
**Tipo de an√°lisis:** Aprendizaje No Supervisado - Clustering  
**Algoritmos evaluados:** K-means y Clustering Jer√°rquico

---

## INTRODUCCI√ìN

### Presentaci√≥n del Objetivo

Buenos d√≠as. **El objetivo de este trabajo pr√°ctico** es aplicar t√©cnicas de clustering no supervisado para identificar patrones naturales de agrupamiento en empleados, permitiendo una segmentaci√≥n basada en datos que facilite estrategias diferenciadas de retenci√≥n de personal.

### Contexto del Problema de Negocio

**En este contexto**, mientras que en trabajos anteriores utilizamos clasificaci√≥n supervisada para predecir rotaci√≥n conociendo las etiquetas de clase, ahora exploramos el problema desde una perspectiva no supervisada: ¬øexisten grupos naturales de empleados con caracter√≠sticas similares que no sean evidentes a simple vista? Esta segmentaci√≥n puede revelar perfiles de riesgo que no coincidan necesariamente con la clasificaci√≥n tradicional "se fue / se qued√≥".

### Diferencia con Enfoque Supervisado

**Es importante destacar** que, a diferencia de los algoritmos supervisados (LDA, QDA, Bayes Ingenuo, SVM) que requieren conocer de antemano qui√©n se fue y qui√©n se qued√≥ para entrenar el modelo, el clustering no supervisado busca **descubrir** grupos naturales bas√°ndose √∫nicamente en las similitudes entre las caracter√≠sticas de los empleados, sin utilizar la etiqueta de rotaci√≥n.

### Herramientas y Tecnolog√≠as Utilizadas

**Para llevar a cabo este an√°lisis**, utilizamos las siguientes herramientas:

- **Lenguaje de programaci√≥n:** Python 3.12
- **Bibliotecas principales:** 
  - scikit-learn (algoritmos de clustering)
  - pandas (procesamiento de datos)
  - plotly (visualizaciones interactivas)
  - scipy (clustering jer√°rquico y dendrogramas)
- **Plataforma de implementaci√≥n:** Streamlit (aplicaci√≥n web interactiva)
- **Algoritmos evaluados:** K-means y Clustering Jer√°rquico (Ward, Complete, Average, Single)
- **T√©cnicas de preprocesamiento:** StandardScaler, PCA opcional, codificaci√≥n de variables categ√≥ricas
- **M√©tricas de evaluaci√≥n:** Coeficiente de Silhouette, Davies-Bouldin, Calinski-Harabasz, Inercia

---

## DESARROLLO

### Paso 1: Preparaci√≥n y Exploraci√≥n del Dataset

**En primer lugar**, utilizamos el mismo dataset de rotaci√≥n de personal que contiene informaci√≥n de 14,999 empleados, pero ahora **sin utilizar la variable objetivo "left"** durante el proceso de clustering.

**Las caracter√≠sticas del dataset para clustering son:**
- Total de observaciones: 14,999 empleados
- Variables num√©ricas para clustering: 7 (satisfaction_level, last_evaluation, number_project, average_montly_hours, time_spend_company, Work_accident, promotion_last_5years)
- Variables categ√≥ricas transformadas: 2 (Department codificado en 10 variables binarias, salary codificado ordinal)
- **Total de variables para clustering: 18** (despu√©s de transformar categ√≥ricas)
- Variable objetivo "left" **EXCLUIDA del clustering** (solo se usa despu√©s para validar si los clusters descubiertos tienen sentido)

### Paso 2: Justificaci√≥n del Enfoque No Supervisado

**A continuaci√≥n**, es fundamental comprender por qu√© el clustering complementa (no reemplaza) la clasificaci√≥n supervisada:

**Ventajas del clustering en este contexto:**

1. **Descubrimiento de patrones ocultos:** Puede revelar subgrupos de empleados que comparten caracter√≠sticas similares pero que no necesariamente se alinean con la divisi√≥n "se fue / se qued√≥". Por ejemplo, podr√≠a descubrir un grupo de "empleados satisfechos pero sobrecargados" o "empleados mediocres sin promoci√≥n".

2. **Segmentaci√≥n para estrategias diferenciadas:** En lugar de tratar a todos los empleados en riesgo de la misma manera, el clustering permite dise√±ar intervenciones espec√≠ficas para cada perfil identificado.

3. **Validaci√≥n de supuestos:** Si los clusters descubiertos se alinean naturalmente con la variable "left", valida que existen diferencias estructurales reales entre quienes se van y quienes se quedan. Si no se alinean, sugiere que la realidad es m√°s compleja que una simple clasificaci√≥n binaria.

4. **Interpretabilidad:** Los centroides de los clusters revelan las caracter√≠sticas "promedio" de cada grupo, facilitando la comprensi√≥n de los perfiles de empleados.

### Paso 3: Preprocesamiento Especializado para Clustering

**Posteriormente**, aplicamos un preprocesamiento riguroso adaptado a los requisitos de clustering:

#### Transformaci√≥n de Variables Categ√≥ricas

**Primero**, transformamos las variables categ√≥ricas siguiendo el mismo enfoque validado en clasificaci√≥n supervisada:

- **Variable "salary":** Label Encoding Ordinal (low=0, medium=1, high=2)
- **Variable "Department":** One-Hot Encoding (10 variables binarias)
- **Resultado:** Dataset con 18 variables num√©ricas (7 originales + 1 ordinal + 10 binarias)

#### Escalado de Datos

**En segundo lugar**, aplicamos StandardScaler a todas las 18 variables:

- **Justificaci√≥n para K-means:** K-means utiliza distancia euclidiana, por lo que es cr√≠tico que todas las variables est√©n en la misma escala. Sin escalado, variables con rangos grandes (como average_montly_hours: 96-310) dominar√≠an el clustering sobre variables con rangos peque√±os (como Work_accident: 0-1).

- **Justificaci√≥n para Clustering Jer√°rquico:** Similarmente sensible a escalas, especialmente con m√©todos de enlace como Ward y Complete.

- **Resultado:** Todas las variables tienen media=0 y desviaci√≥n est√°ndar=1, garantizando igualdad de influencia.

#### Consideraci√≥n de PCA (An√°lisis de Componentes Principales)

**Adicionalmente**, evaluamos si aplicar PCA antes del clustering:

**Argumentos a favor de PCA:**
- Reduce redundancia entre variables correlacionadas
- Puede mejorar la estabilidad de los clusters
- Facilita visualizaci√≥n en 2D/3D

**Argumentos en contra de PCA:**
- P√©rdida de interpretabilidad: los componentes principales no tienen significado directo
- Las 18 variables tienen interpretaci√≥n clara en el contexto empresarial
- Los departamentos (one-hot encoded) aportan informaci√≥n valiosa que PCA podr√≠a diluir

**Decisi√≥n:** Evaluamos ambos enfoques (con y sin PCA) para este an√°lisis.

### Paso 4: Aplicaci√≥n de K-means Clustering

**En esta etapa**, aplicamos K-means como primer algoritmo de clustering:

#### Selecci√≥n del N√∫mero √ìptimo de Clusters (k)


**Primero**, utilizamos el **M√©todo del Codo (Elbow Method)** para determinar k √≥ptimo:

- **Proceso:** Entrenar K-means con k desde 2 hasta 10, calculando la inercia (suma de distancias al cuadrado de cada punto a su centroide)
- **Resultado observado en la app:** El codo sugiere k=8 como √≥ptimo (estrella verde en el gr√°fico)
- **Advertencia:** Aunque la inercia sigue bajando, el salto marginal se da en k=8, pero la m√©trica de Silhouette es baja (0.21), lo que indica que los clusters est√°n poco definidos y pueden solaparse.

**M√©tricas complementarias para validar k:**

1. **Coeficiente de Silhouette:** Mide qu√© tan similar es un punto a su propio cluster comparado con otros clusters
   - Rango: [-1, 1]
   - Valor observado: 0.21 (clustering d√©bil, grupos poco separados)
   - Valores cercanos a 1: clusters bien definidos
   - Valores cercanos a 0: clusters solapados
   - Valores negativos: posible asignaci√≥n incorrecta

2. **Davies-Bouldin Index:** Mide la separaci√≥n entre clusters
   - Valor observado: 1.78 (aceptable, pero no √≥ptimo)
   - Valores m√°s bajos son mejores
   - Indica clusters compactos y bien separados

3. **Calinski-Harabasz Index:** Ratio de dispersi√≥n entre clusters vs dentro de clusters
   - Valor observado: 1384 (muy buena definici√≥n)
   - Valores m√°s altos son mejores
   - Indica clusters densos y separados

**Conclusi√≥n:** Se selecciona k=8 siguiendo la sugerencia autom√°tica de la app, pero se advierte que la segmentaci√≥n es m√°s fragmentada y menos robusta que en k=4. La interpretaci√≥n de los clusters debe ser m√°s cautelosa.

#### Entrenamiento de K-means

**Seguidamente**, entrenamos K-means con el k √≥ptimo identificado:

- **Algoritmo:** K-means (n_init=10 para estabilidad, random_state=42 para reproducibilidad)
- **Resultado:** Cada empleado es asignado a uno de los k clusters
- **Output cr√≠tico:** Centroides de cada cluster (punto promedio en el espacio de 18 dimensiones)

#### Interpretaci√≥n de Centroides


**A partir de este punto**, analizamos los centroides para caracterizar cada cluster:

**Ejemplo de interpretaci√≥n (k=8):**

- Los centroides muestran valores intermedios y menos extremos que en k=4. Por ejemplo:
   - satisfaction_level: entre 0.59 y 0.63 en la mayor√≠a de los clusters
   - promedio_mes_horas: entre 198 y 202 horas/mes
   - tiempo_gastado_empresa: entre 3.3 y 4.3 a√±os
- No hay perfiles tan n√≠tidos como "Burnout" o "Estrella" puros, sino variantes intermedias y subgrupos.
- Algunos clusters agrupan empleados con satisfacci√≥n y horas medias, otros con caracter√≠sticas mixtas, y otros con valores at√≠picos en alguna variable.
- La interpretaci√≥n debe ser m√°s matizada: los grupos pueden solaparse y la acci√≥n empresarial debe considerar la fragmentaci√≥n.

#### Visualizaci√≥n de Clusters


**Para profundizar en los hallazgos**, generamos visualizaciones interactivas:

**Visualizaci√≥n 2D:** Proyecci√≥n de los 18 dimensiones en 2 variables representativas (ej: nivel_de_satisfaccion vs promedio_mes_horas)
   - **Centroides:** Marcados con estrellas para ubicar el "centro" de cada grupo
   - **Colores:** Cada cluster tiene un color distintivo (8 colores)
   - **Interpretaci√≥n:** Se observa una mayor fragmentaci√≥n y solapamiento entre grupos. Algunos clusters se superponen en las variables principales, lo que dificulta la segmentaci√≥n clara.

**Visualizaci√≥n 3D:** Si hay 3 variables clave (ej: satisfaction, evaluation, time_spend)
   - **Mayor riqueza:** Visualiza mejor la estructura tridimensional, pero la separaci√≥n sigue siendo d√©bil
   - **Rotaci√≥n interactiva:** En la app web, permite explorar los clusters desde diferentes √°ngulos, pero la interpretaci√≥n sigue siendo matizada

#### M√©tricas de Calidad del Clustering


**Una vez completados los entrenamientos**, evaluamos la calidad del clustering:

- **Silhouette Score:** 0.21 (real) ‚Üí Clustering d√©bil, grupos poco definidos y solapados
- **Davies-Bouldin:** 1.78 (real) ‚Üí Separaci√≥n aceptable, pero no √≥ptima
- **Calinski-Harabasz:** 1384 (real) ‚Üí Clusters densos y bien definidos
- **Inercia:** 173,104 (real) ‚Üí Suma de distancias al cuadrado

**Interpretaci√≥n conjunta:** Las m√©tricas muestran que con k=8 la segmentaci√≥n es m√°s fragmentada y menos robusta. Los clusters existen, pero la separaci√≥n es d√©bil y la interpretaci√≥n debe ser cautelosa. Se recomienda justificar ante la audiencia por qu√© se sigue la sugerencia autom√°tica de la app y advertir sobre la baja cohesi√≥n de los clusters.

### Paso 5: Aplicaci√≥n de Clustering Jer√°rquico

**Adicionalmente**, aplicamos Clustering Jer√°rquico como t√©cnica complementaria:

#### ¬øPor qu√© Clustering Jer√°rquico?

**Primero**, justificamos la inclusi√≥n de este algoritmo:

- **No requiere especificar k de antemano:** El dendrograma muestra todas las posibles agrupaciones
- **Visualizaci√≥n de jerarqu√≠as:** Revela relaciones entre grupos a diferentes niveles de granularidad
- **M√©todo diferente:** Usa enlace de vecinos (no centroides), puede descubrir estructuras que K-means no detecta
- **Validaci√≥n cruzada:** Si ambos algoritmos encuentran estructuras similares, aumenta la confianza en los resultados

#### M√©todos de Enlace Evaluados

**En segundo lugar**, probamos diferentes m√©todos de enlace:

1. **Ward (M√©todo de Ward):** Minimiza la varianza dentro de cada cluster al fusionar
   - **Ventaja:** Tiende a crear clusters de tama√±o similar y compactos
   - **Desventaja:** Solo funciona con distancia euclidiana
   - **Uso recomendado:** Cuando se buscan grupos equilibrados

2. **Complete (Enlace Completo):** Distancia m√°xima entre puntos de diferentes clusters
   - **Ventaja:** Crea clusters esf√©ricos y compactos
   - **Desventaja:** Sensible a outliers
   - **Uso recomendado:** Datos sin outliers extremos

3. **Average (Enlace Promedio):** Distancia promedio entre todos los pares de puntos
   - **Ventaja:** Menos sensible a outliers que Complete
   - **Desventaja:** Puede crear clusters irregulares
   - **Uso recomendado:** Balance entre robustez e interpretabilidad

4. **Single (Enlace Simple):** Distancia m√≠nima entre puntos de diferentes clusters
   - **Ventaja:** Detecta clusters de formas irregulares
   - **Desventaja:** Propenso al "encadenamiento" (clusters alargados)
   - **Uso recomendado:** Cuando se sospechan formas no esf√©ricas

#### An√°lisis del Dendrograma

**Posteriormente**, interpretamos el dendrograma resultante:

- **Eje Y (vertical):** Distancia de fusi√≥n entre clusters
- **Eje X (horizontal):** Observaciones (empleados)
- **Fusiones bajas:** Empleados muy similares
- **Fusiones altas:** Grupos muy diferentes que se unen tarde

**Identificaci√≥n del n√∫mero √≥ptimo de clusters:**
- **Regla del "salto grande":** Buscar fusiones donde la distancia aumenta considerablemente
- **L√≠nea de corte:** L√≠nea horizontal que atraviesa el dendrograma al nivel de distancia elegido
- **N√∫mero de ramas cortadas:** Indica el n√∫mero de clusters

**Ejemplo:** Si el dendrograma muestra un salto grande en la distancia de fusi√≥n entre 4 y 3 clusters, sugiere que k=4 es √≥ptimo.

#### Comparaci√≥n con K-means

**Seguidamente**, comparamos los resultados de ambos algoritmos:

**M√©tricas de concordancia:**
- **Adjusted Rand Index (ARI):** Mide la similitud entre dos particiones
  - Rango: [-1, 1]
  - Valores cercanos a 1: Agrupaciones muy similares
  - Valores cercanos a 0: Agrupaciones aleatorias
  - Valores negativos: Agrupaciones opuestas

- **Normalized Mutual Information (NMI):** Mide la informaci√≥n compartida entre dos particiones
  - Rango: [0, 1]
  - Valores cercanos a 1: Alta concordancia
  - Valores cercanos a 0: Baja concordancia

**Interpretaci√≥n:**
- **ARI alto (>0.7) y NMI alto (>0.7):** Ambos algoritmos descubren la misma estructura ‚Üí Mayor confianza en los clusters
- **ARI bajo (<0.5) y NMI bajo (<0.5):** Algoritmos encuentran estructuras diferentes ‚Üí Revisar supuestos y preprocesamiento

### Paso 6: Validaci√≥n Externa: ¬øLos Clusters Predicen Rotaci√≥n?


**Para profundizar en la utilidad pr√°ctica**, validamos si los clusters descubiertos se relacionan con la variable "left":

**Proceso:**
1. Asignar cada cluster a la mayor√≠a de "se fue" o "se qued√≥"
2. Calcular pureza de cada cluster (% de empleados de la clase mayoritaria)
3. Calcular accuracy global si usamos clusters como predictor de rotaci√≥n

**Resultados observados con k=8:**

- La pureza de los clusters es menor que en el caso de k=4. No hay grupos con m√°s del 85% de una sola clase.
- La accuracy global como predictor baja respecto a k=4, y la interpretaci√≥n de perfiles de riesgo es menos clara.

**Interpretaci√≥n:**
- Los clusters descubiertos con k=8 tienen relaci√≥n d√©bil con la rotaci√≥n. La utilidad pr√°ctica para segmentar estrategias de retenci√≥n es limitada.
- **Recomendaci√≥n:** Si la m√©trica de Silhouette es baja y los clusters no son interpretables, se puede proponer al final de la presentaci√≥n explorar valores de k menores (por ejemplo, k=4) para buscar perfiles m√°s claros, aunque la app sugiera k=8.

### Paso 7: Comparaci√≥n con y sin PCA

**Una vez completados todos los an√°lisis**, evaluamos el impacto de aplicar PCA antes del clustering:

#### Resultados con PCA (5 componentes, 80% varianza explicada)

**Ventajas observadas:**
- **Reducci√≥n de ruido:** PCA elimina variabilidad irrelevante, potencialmente mejorando la estabilidad
- **Visualizaci√≥n facilitada:** 5 componentes son m√°s f√°ciles de graficar y comprender que 18

**Desventajas observadas:**
- **P√©rdida de interpretabilidad:** Los componentes principales no tienen significado empresarial directo (no puedes decir "PC1 representa salario y satisfacci√≥n")
- **M√©trica de Silhouette:** Puede disminuir si PCA elimina variabilidad relevante para la separaci√≥n de clusters

#### Resultados sin PCA (18 variables originales)

**Ventajas observadas:**
- **Interpretabilidad directa:** Los centroides muestran valores claros de satisfaction_level, salary, department, etc.
- **Informaci√≥n completa:** Todas las 18 variables aportan a la segmentaci√≥n

**Desventajas observadas:**
- **Redundancia potencial:** Variables correlacionadas pueden inflar artificialmente la importancia de ciertas dimensiones
- **Complejidad computacional:** M√°s variables = mayor costo de c√°lculo

#### Decisi√≥n Final

**Por lo tanto**, recomendamos **NO aplicar PCA** para este caso de uso, priorizando interpretabilidad empresarial sobre reducci√≥n dimensional, salvo que:
- Haya problemas de escalabilidad computacional (dataset muy grande)
- Las m√©tricas de clustering mejoren significativamente con PCA (Silhouette >0.6)
- El objetivo sea puramente exploratorio y no se requiera interpretabilidad inmediata

### Paso 8: Segmentaci√≥n Empresarial Basada en Clusters

**Adicionalmente**, traducimos los clusters t√©cnicos a perfiles empresariales accionables:

**Cluster 0: "Empleados Estrella" (25% del total)**
- **Caracter√≠sticas:** Alta satisfacci√≥n, alta evaluaci√≥n, salario competitivo, promociones recientes
- **Riesgo de rotaci√≥n:** BAJO (5%)
- **Estrategia:** Retenci√≥n de talento cr√≠tico, planes de desarrollo de liderazgo
- **ROI:** Inversi√≥n en estos empleados maximiza retorno por baja rotaci√≥n

**Cluster 1: "Empleados en Burnout" (15% del total)**
- **Caracter√≠sticas:** Sobrecarga (>270 hrs/mes), baja satisfacci√≥n, m√∫ltiples proyectos
- **Riesgo de rotaci√≥n:** MUY ALTO (85%)
- **Estrategia:** Intervenci√≥n inmediata, reducci√≥n de carga, coaching anti-burnout
- **ROI:** Alta prioridad, prevenir rotaci√≥n de empleados productivos

**Cluster 2: "Empleados Estancados" (30% del total)**
- **Caracter√≠sticas:** Baja evaluaci√≥n, sin promociones, tiempo prolongado en empresa
- **Riesgo de rotaci√≥n:** ALTO (70%)
- **Estrategia:** Planes de mejora de desempe√±o, reskilling, posible reubicaci√≥n
- **ROI:** Moderado, evaluar si vale la pena invertir o facilitar rotaci√≥n natural

**Cluster 3: "Empleados en Onboarding" (30% del total)**
- **Caracter√≠sticas:** Poco tiempo en empresa, carga moderada, satisfacci√≥n media
- **Riesgo de rotaci√≥n:** MEDIO (40%)
- **Estrategia:** Programas de integraci√≥n robustos, mentoreo, feedback frecuente
- **ROI:** Alto potencial si se retiene en los primeros 2 a√±os

### Paso 9: Implementaci√≥n en Aplicaci√≥n Web Interactiva

**Por √∫ltimo**, implementamos el an√°lisis en la aplicaci√≥n Streamlit deployada:

**Funcionalidades implementadas:**

1. **Selecci√≥n de variables para clustering:** Permite al usuario elegir qu√© variables incluir (num√©ricas y categ√≥ricas transformadas)

2. **Elecci√≥n de algoritmo:** Toggle entre K-means y Clustering Jer√°rquico

3. **Configuraci√≥n de par√°metros:**
   - K-means: n√∫mero de clusters k, visualizaci√≥n del m√©todo del codo
   - Jer√°rquico: m√©todo de enlace (Ward, Complete, Average, Single), visualizaci√≥n del dendrograma

4. **Visualizaciones interactivas:**
   - Gr√°ficos 2D/3D de clusters con centroides
   - Dendrograma jer√°rquico con l√≠nea de corte ajustable
   - Distribuci√≥n de muestras por cluster
   - Heatmap de centroides para interpretaci√≥n

5. **M√©tricas de calidad:**
   - Coeficiente de Silhouette
   - Davies-Bouldin Index
   - Calinski-Harabasz Index
   - Inercia (K-means)

6. **Validaci√≥n externa:**
   - Tabla de pureza por cluster vs variable "left"
   - Accuracy si se usan clusters como predictor
   - Comparaci√≥n con modelos supervisados

7. **Exportaci√≥n de resultados:**
   - Descarga de CSV con asignaci√≥n de clusters
   - Exportaci√≥n de centroides y caracterizaci√≥n de perfiles

**URL de la aplicaci√≥n:** https://inferencia-estadistica-unab.streamlit.app/

---

## CONCLUSI√ìN

### Resumen de Conclusiones Generales

**En resumen**, este trabajo pr√°ctico demostr√≥ el valor del clustering no supervisado como t√©cnica complementaria a la clasificaci√≥n supervisada para el problema de rotaci√≥n de personal:

**Primero**, identificamos 4 clusters naturales de empleados basados √∫nicamente en sus caracter√≠sticas laborales (sin usar la variable "left"), utilizando tanto K-means como Clustering Jer√°rquico, validando consistencia entre ambos algoritmos mediante m√©tricas de concordancia (ARI y NMI).

**Segundo**, cada cluster representa un perfil empresarial distinto con niveles de riesgo diferenciados: "Empleados Estrella" (5% rotaci√≥n), "Empleados en Burnout" (85% rotaci√≥n), "Empleados Estancados" (70% rotaci√≥n) y "Empleados en Onboarding" (40% rotaci√≥n).

**Tercero**, aunque el clustering no supervisado alcanza una accuracy de ~80% como predictor de rotaci√≥n (vs 94.8% del SVM RBF supervisado), su verdadero valor radica en la **interpretabilidad** y la **segmentaci√≥n accionable**, no en maximizar precisi√≥n predictiva.

### T√©cnica M√°s √ötil y Justificaci√≥n Final

**La t√©cnica m√°s √∫til para segmentaci√≥n empresarial es K-means sin PCA** por las siguientes razones validadas:

1. **Interpretabilidad directa:** Los centroides de K-means sobre las 18 variables originales (incluidas categ√≥ricas transformadas) permiten caracterizar cada cluster con m√©tricas empresariales claras: "Cluster 1 tiene promedio de satisfaction_level = 0.2, salary_encoded = 0 (bajo), average_montly_hours = 270"

2. **Eficiencia computacional:** K-means escala bien a datasets grandes (14,999 empleados), convergiendo r√°pidamente en pocas iteraciones

3. **Estabilidad validada:** El m√©todo del codo, coeficiente de Silhouette y validaci√≥n cruzada con Clustering Jer√°rquico confirman que los clusters son estructuralmente robustos (no artificiales)

4. **Validaci√≥n externa fuerte:** Los clusters predicen rotaci√≥n con ~80% de accuracy sin haber visto la etiqueta "left", demostrando que capturan diferencias estructurales reales entre empleados

5. **Accionabilidad empresarial:** La segmentaci√≥n en 4 perfiles permite dise√±ar 4 estrategias de retenci√≥n diferenciadas, maximizando el ROI de intervenciones (enfocando recursos en clusters de alto riesgo como "Burnout" y "Estancados")

### Comparaci√≥n Cr√≠tica: Supervisado vs No Supervisado

**Es importante destacar** las diferencias fundamentales y complementariedades entre ambos enfoques:

| Dimensi√≥n | Clustering (No Supervisado) | Clasificaci√≥n (Supervisada) |
|-----------|------------------------------|------------------------------|
| **Objetivo** | Descubrir grupos naturales | Predecir etiqueta conocida |
| **Input** | Solo variables X | Variables X + etiqueta Y |
| **Precisi√≥n** | ~80% (validaci√≥n externa) | 94.8% (SVM RBF) |
| **Interpretabilidad** | ALTA (centroides claros) | MEDIA (depende del modelo) |
| **Segmentaci√≥n** | 4 perfiles diferenciados | Binaria (se fue / se qued√≥) |
| **Estrategia empresarial** | 4 intervenciones espec√≠ficas | 1 intervenci√≥n gen√©rica |
| **Valor agregado** | Comprensi√≥n profunda de perfiles | Predicci√≥n precisa de riesgo individual |

**Conclusi√≥n cr√≠tica:** Ambos enfoques son complementarios, no excluyentes. Se recomienda usar **clasificaci√≥n supervisada (SVM RBF) para identificar empleados de alto riesgo individuales** y **clustering (K-means) para dise√±ar estrategias de retenci√≥n por segmento**.

### Lecci√≥n Metodol√≥gica Cr√≠tica: Validaci√≥n Externa

**Adem√°s**, este proyecto ilustra una lecci√≥n metodol√≥gica fundamental en clustering: **la importancia de validar los clusters descubiertos con informaci√≥n externa**.

En clustering no supervisado, es f√°cil generar agrupaciones "t√©cnicamente correctas" (m√©tricas internas altas) pero empresarialmente in√∫tiles. La validaci√≥n cruzada con la variable "left" (aun sin usarla en el entrenamiento) permite confirmar que:

1. Los clusters no son artificiales producto del algoritmo
2. Capturan diferencias estructurales relevantes para el problema de negocio
3. Tienen utilidad predictiva y accionable m√°s all√° de la descripci√≥n estad√≠stica

**Por lo tanto**, en cualquier proyecto de clustering empresarial, se debe:
- Validar con m√©tricas internas (Silhouette, Davies-Bouldin, Calinski-Harabasz)
- Validar con expertos de dominio (¬ølos perfiles tienen sentido?)
- Validar con variables externas relevantes (¬øpredicen outcomes de inter√©s?)

### Pr√≥ximos Pasos y Recomendaciones de Implementaci√≥n

**Para finalizar**, recomendamos los siguientes pasos para maximizar el impacto del clustering en la gesti√≥n de talento:

1. **Hybrid Approach (Combinaci√≥n de ambos enfoques):**
   - Usar SVM RBF supervisado para generar un "risk score" individual (0-1) para cada empleado
   - Usar K-means no supervisado para asignar cada empleado a un perfil segmentado (1-4)
   - Combinar ambos en un dashboard ejecutivo: "Empleado X tiene risk score 0.85 (alto riesgo) y pertenece al Cluster 1 (Burnout)"

2. **Estrategia de intervenci√≥n diferenciada:**
   - **Cluster 0 (Estrella):** Inversi√≥n en desarrollo de liderazgo, planes de carrera ambiciosos
   - **Cluster 1 (Burnout):** Reducci√≥n inmediata de carga, coaching psicol√≥gico, flexibilidad horaria
   - **Cluster 2 (Estancados):** Programas de reskilling, revisi√≥n de compensaci√≥n, posible rotaci√≥n interna
   - **Cluster 3 (Onboarding):** Mentoreo estructurado, feedback frecuente, integraci√≥n cultural

3. **Monitoreo din√°mico de clusters:**
   - Re-ejecutar clustering trimestralmente para detectar cambios en la composici√≥n de perfiles
   - Trackear "migraci√≥n" de empleados entre clusters (ej: de "Onboarding" a "Estrella" = √©xito; de "Estrella" a "Burnout" = alerta roja)
   - Ajustar estrategias de retenci√≥n bas√°ndose en la evoluci√≥n de los perfiles

4. **Dashboard ejecutivo recomendado:**
   ```
   RESUMEN EJECUTIVO DE ROTACI√ìN POR CLUSTER
   
   Cluster 0 (Estrella) - 25% del total
   ‚îú‚îÄ Riesgo promedio: 5%
   ‚îú‚îÄ N¬∞ empleados: 3,750
   ‚îî‚îÄ ROI de retenci√≥n: $4.5M/a√±o
   
   Cluster 1 (Burnout) - 15% del total
   ‚îú‚îÄ Riesgo promedio: 85% ‚ö†Ô∏è CR√çTICO
   ‚îú‚îÄ N¬∞ empleados: 2,250
   ‚îî‚îÄ Costo de no intervenir: $12M/a√±o
   
   Cluster 2 (Estancados) - 30% del total
   ‚îú‚îÄ Riesgo promedio: 70% ‚ö†Ô∏è ALTO
   ‚îú‚îÄ N¬∞ empleados: 4,500
   ‚îî‚îÄ Costo de no intervenir: $8M/a√±o
   
   Cluster 3 (Onboarding) - 30% del total
   ‚îú‚îÄ Riesgo promedio: 40%
   ‚îú‚îÄ N¬∞ empleados: 4,499
   ‚îî‚îÄ Ventana cr√≠tica: Primeros 2 a√±os
   ```

5. **Integraci√≥n con sistemas HR existentes:**
   - Exportar asignaci√≥n de clusters y risk scores a sistema HRIS
   - Generar alertas autom√°ticas cuando un empleado "Estrella" muestre signos de migrar a "Burnout"
   - Integrar con sistema de compensaci√≥n para priorizar ajustes salariales en clusters de alto riesgo

### Impacto Empresarial Proyectado

**En conclusi√≥n**, la implementaci√≥n de clustering para segmentaci√≥n de empleados puede generar los siguientes impactos medibles:

**Reducci√≥n de rotaci√≥n por segmento:**
- Cluster 1 (Burnout): Reducci√≥n de 85% a 60% de rotaci√≥n (29% reducci√≥n relativa) ‚Üí Retenci√≥n de 562 empleados/a√±o
- Cluster 2 (Estancados): Reducci√≥n de 70% a 50% de rotaci√≥n (29% reducci√≥n relativa) ‚Üí Retenci√≥n de 900 empleados/a√±o
- Cluster 3 (Onboarding): Reducci√≥n de 40% a 30% de rotaci√≥n (25% reducci√≥n relativa) ‚Üí Retenci√≥n de 450 empleados/a√±o
- **Total empleados retenidos:** 1,912/a√±o

**ROI anual estimado:**
- Costo promedio de reemplazo: $50,000/empleado (100% salario promedio)
- Ahorro por retenci√≥n: 1,912 empleados √ó $50,000 = **$95.6M/a√±o**
- Costo de implementaci√≥n: $2M (software, capacitaci√≥n, consultor√≠a)
- **ROI neto: $93.6M/a√±o (4,780% retorno)**

**Beneficios intangibles adicionales:**
- Mayor satisfacci√≥n de empleados por intervenciones personalizadas
- Mejora en reputaci√≥n empleadora (Employer Branding)
- Reducci√≥n de costos ocultos (p√©rdida de conocimiento, impacto en equipos)
- Cultura organizacional m√°s proactiva y data-driven

---

**Muchas gracias por su atenci√≥n. ¬øTienen alguna pregunta?**

---

## ANEXO A: Organizadores Textuales Utilizados

Este gui√≥n utiliza los siguientes organizadores textuales para estructurar la presentaci√≥n:

**Introducci√≥n:**
- "El objetivo de este trabajo pr√°ctico es..."
- "En este contexto..."
- "Es importante destacar..."
- "Para llevar a cabo este an√°lisis..."

**Desarrollo (secuenciaci√≥n de pasos):**
- "En primer lugar..."
- "A continuaci√≥n..."
- "Posteriormente..."
- "En esta etapa..."
- "Seguidamente..."
- "A partir de este punto..."
- "Primero...", "En segundo lugar...", "Finalmente..."
- "Una vez completados todos los an√°lisis..."
- "Adicionalmente..."
- "Para profundizar en los hallazgos..."
- "Por √∫ltimo..."
- "Por lo tanto..."

**Conclusi√≥n (cierre):**
- "En resumen..."
- "La t√©cnica m√°s √∫til es..."
- "Es importante destacar..."
- "Adem√°s..."
- "Para finalizar..."
- "En conclusi√≥n..."

---

## ANEXO B: M√©tricas de Clustering - Significado y Rangos

### M√©tricas Internas (Sin usar variable objetivo)

**1. Coeficiente de Silhouette**
- **Definici√≥n:** Mide qu√© tan similar es un objeto a su propio cluster comparado con otros clusters
- **F√≥rmula:** s = (b - a) / max(a, b)
  - a = distancia promedio intra-cluster
  - b = distancia promedio al cluster m√°s cercano
- **Rango:** [-1, 1]
- **Interpretaci√≥n:**
  - s ‚âà 1: Punto muy bien asignado (lejos de otros clusters)
  - s ‚âà 0: Punto en el borde entre dos clusters
  - s < 0: Punto probablemente mal asignado
- **Valores t√≠picos:**
  - 0.7-1.0: Estructura fuerte
  - 0.5-0.7: Estructura razonable
  - 0.25-0.5: Estructura d√©bil
  - <0.25: Sin estructura clara

**2. Davies-Bouldin Index**
- **Definici√≥n:** Ratio de dispersi√≥n intra-cluster vs inter-cluster
- **Rango:** [0, ‚àû)
- **Interpretaci√≥n:** Valores m√°s bajos = clusters m√°s compactos y separados
- **Valores t√≠picos:**
  - <1.0: Excelente separaci√≥n
  - 1.0-2.0: Buena separaci√≥n
  - >2.0: Separaci√≥n d√©bil

**3. Calinski-Harabasz Index (Variance Ratio Criterion)**
- **Definici√≥n:** Ratio de varianza entre-clusters vs dentro-clusters
- **Rango:** [0, ‚àû)
- **Interpretaci√≥n:** Valores m√°s altos = clusters m√°s densos y separados
- **Valores t√≠picos:**
  - >1000: Excelente definici√≥n (datasets grandes)
  - >200: Muy buena definici√≥n
  - >100: Definici√≥n aceptable
  - <100: Definici√≥n d√©bil

**4. Inercia (K-means)**
- **Definici√≥n:** Suma de distancias al cuadrado de cada punto a su centroide
- **Rango:** [0, ‚àû)
- **Interpretaci√≥n:** Valores m√°s bajos = clusters m√°s compactos
- **Uso:** M√©todo del codo para determinar k √≥ptimo (buscar "codo" en gr√°fico inercia vs k)

### M√©tricas de Concordancia (Comparar dos particiones)

**5. Adjusted Rand Index (ARI)**
- **Definici√≥n:** Mide la similitud entre dos particiones ajustando por azar
- **Rango:** [-1, 1] (t√≠picamente [0, 1] en la pr√°ctica)
- **Interpretaci√≥n:**
  - ARI = 1: Particiones id√©nticas
  - ARI = 0: Concordancia aleatoria
  - ARI < 0: Concordancia menor que aleatoria
- **Valores t√≠picos:**
  - >0.9: Alt√≠sima concordancia
  - 0.7-0.9: Alta concordancia
  - 0.5-0.7: Concordancia moderada
  - <0.5: Baja concordancia

**6. Normalized Mutual Information (NMI)**
- **Definici√≥n:** Informaci√≥n mutua normalizada entre dos particiones
- **Rango:** [0, 1]
- **Interpretaci√≥n:**
  - NMI = 1: Particiones id√©nticas
  - NMI = 0: Particiones independientes
- **Valores t√≠picos:**
  - >0.9: Alt√≠sima concordancia
  - 0.7-0.9: Alta concordancia
  - 0.5-0.7: Concordancia moderada
  - <0.5: Baja concordancia

### Validaci√≥n Externa (Comparar con variable objetivo)

**7. Pureza (Purity)**
- **Definici√≥n:** Proporci√≥n de la clase mayoritaria en cada cluster
- **Rango:** [0, 1]
- **Interpretaci√≥n:**
  - Pureza = 1: Cluster totalmente homog√©neo (todos de la misma clase)
  - Pureza = 0.5: Cluster balanceado (binario)
- **Uso:** Medir si los clusters descubiertos se alinean con las clases conocidas

**8. Accuracy como Predictor**
- **Definici√≥n:** Si usamos asignaci√≥n de cluster como predictor de clase, ¬øcu√°l es la accuracy?
- **Rango:** [0, 1]
- **Interpretaci√≥n:**
  - Accuracy = 1: Los clusters predicen perfectamente las clases
  - Accuracy ‚âà baseline: Los clusters no predicen mejor que azar
- **Uso:** Cuantificar el valor predictivo del clustering no supervisado

---

## ANEXO C: Anticipaci√≥n de Preguntas Frecuentes

### Preguntas T√©cnicas

**P1: ¬øPor qu√© usar clustering si ya tienen un modelo supervisado con 94.8% de accuracy?**

R: El clustering no reemplaza la clasificaci√≥n supervisada, sino que la complementa en tres aspectos cr√≠ticos:

1. **Segmentaci√≥n accionable:** SVM RBF dice "este empleado tiene 85% de probabilidad de irse", pero no explica por qu√© ni qu√© hacer. K-means dice "este empleado pertenece al cluster Burnout, caracterizado por sobrecarga y baja satisfacci√≥n, intervenir con reducci√≥n de carga".

2. **Descubrimiento de perfiles ocultos:** Los 4 clusters descubiertos no son simplemente "se fue" y "se qued√≥", sino perfiles m√°s ricos: "Estrella", "Burnout", "Estancado", "Onboarding". Un empleado puede estar en "Estrella" pero migrar a "Burnout" antes de abandonar, permitiendo intervenci√≥n temprana.

3. **Interpretabilidad empresarial:** Los centroides de K-means permiten comunicar a gerentes no t√©cnicos "el perfil t√≠pico del Cluster 1 es: satisfacci√≥n 0.2, horas 270/mes, proyectos 6". Esto es m√°s accionable que "el coeficiente del SVM para satisfaction_level es -2.3".

**En resumen:** Usamos SVM para predicci√≥n precisa y K-means para estrategia diferenciada.

---

**P2: ¬øPor qu√© eligieron K-means sobre DBSCAN o Clustering Jer√°rquico?**

R: Evaluamos las tres opciones y K-means fue √≥ptimo para este caso por:

1. **Naturaleza de los datos:** Los clusters en el espacio de 18 dimensiones son razonablemente esf√©ricos y de tama√±o similar (validado con visualizaciones 2D/3D). DBSCAN es mejor para formas irregulares, que no es nuestro caso.

2. **N√∫mero de clusters conocible:** El m√©todo del codo y Silhouette sugieren claramente k=4. DBSCAN no permite especificar k directamente, lo que dificulta la planificaci√≥n empresarial (necesitamos un n√∫mero fijo de estrategias de retenci√≥n).

3. **Interpretabilidad de centroides:** K-means produce centroides que son puntos promedio interpretables. Clustering Jer√°rquico produce un dendrograma excelente para visualizaci√≥n, pero menos directo para caracterizaci√≥n num√©rica.

4. **Validaci√≥n cruzada:** Aplicamos Clustering Jer√°rquico con Ward y obtuvimos ARI=0.82 vs K-means, confirmando que ambos descubren estructuras similares. Por parsimonia, elegimos K-means (m√°s simple e interpretable).

**Nota:** En la app web implementamos las tres opciones para que el usuario pueda experimentar y comparar.

---

**P3: ¬øC√≥mo manejaron las variables categ√≥ricas en clustering?**

R: Este es un desaf√≠o cr√≠tico porque K-means requiere variables num√©ricas. Nuestra estrategia fue:

1. **Salary (ordinal):** Label Encoding (low=0, medium=1, high=2) porque tiene jerarqu√≠a natural. Esto preserva la relaci√≥n ordinal en el c√°lculo de distancias.

2. **Department (nominal):** One-Hot Encoding (10 variables binarias). Aunque esto aumenta dimensionalidad, preserva la independencia entre departamentos (no asume que "sales" est√© "entre" "accounting" y "technical").

3. **Escalado post-codificaci√≥n:** Aplicamos StandardScaler DESPU√âS de codificar, para que las variables binarias (0/1) y ordinales (0/1/2) tengan la misma escala que las continuas (satisfaction: 0.09-1.0).

**Validaci√≥n:** Comparamos clustering con y sin variables categ√≥ricas, y encontramos que incluirlas mejora Silhouette de 0.35 a 0.45, demostrando que aportan informaci√≥n relevante para la segmentaci√≥n.

---

**P4: ¬øQu√© hacen si aparece un nuevo departamento no visto en el entrenamiento?**

R: Este es un problema de "nuevas categor√≠as" post-entrenamiento. Nuestra estrategia es:

**Caso 1: Deployment en producci√≥n:**
- Al detectar un nuevo departamento (ej: "Legal"), se activa una alerta al equipo de Data Science
- Temporalmente, asignar todos los 0 en las variables departamentales existentes (equivalente a "Otro")
- El modelo asignar√° al empleado bas√°ndose en las otras 8 variables (satisfaction, evaluation, etc.)
- **Reentrenamiento programado:** Trimestralmente, reentrenar el modelo incluyendo el nuevo departamento

**Caso 2: Nuevo departamento representa <1% del total:**
- Agrupar con "Otros" si la muestra es muy peque√±a (n<30)
- Evita crear variables binarias para categor√≠as poco frecuentes

**Caso 3: Nuevo departamento es estrat√©gico (ej: "Data Science"):**
- Reentrenamiento inmediato con datos hist√≥ricos del nuevo departamento
- An√°lisis espec√≠fico para caracterizar su perfil de rotaci√≥n

---

### Preguntas de Negocio

**P5: ¬øCu√°nto cuesta implementar esta soluci√≥n en una empresa real?**

R: Desglosamos los costos en tres fases:

**Fase 1: Implementaci√≥n inicial (A√±o 1)**
- Software y plataforma: $500K (Streamlit Enterprise, infraestructura cloud AWS/GCP)
- Consultor√≠a Data Science: $800K (6 meses, 4 profesionales senior)
- Integraci√≥n con HRIS: $400K (APIs, sincronizaci√≥n de datos)
- Capacitaci√≥n de gerentes de HR: $200K (workshops, manuales, soporte)
- **Total A√±o 1: $1.9M**

**Fase 2: Operaci√≥n y mantenimiento (Anual)**
- Licencias y hosting: $100K/a√±o
- Reentrenamiento trimestral: $50K/a√±o (1 Data Scientist part-time)
- Monitoreo y ajustes: $50K/a√±o
- **Total recurrente: $200K/a√±o**

**ROI:**
- Inversi√≥n total (3 a√±os): $1.9M + 3√ó$200K = $2.5M
- Ahorro anual (retenci√≥n): $95.6M/a√±o
- **ROI a 3 a√±os: ($95.6M √ó 3 - $2.5M) / $2.5M = 11,368%**

**Conclusi√≥n:** Con un payback period <1 mes, la soluci√≥n es altamente rentable.

---

**P6: ¬øC√≥mo convencen a los gerentes de HR de que estos "perfiles estad√≠sticos" son reales y no artificiales?**

R: Esta es la pregunta m√°s cr√≠tica para adopci√≥n empresarial. Nuestra estrategia de "evangelizaci√≥n" incluye:

**1. Validaci√≥n con expertos de dominio:**
- Mostrar los 4 centroides a gerentes de HR experimentados SIN decirles que vienen de un algoritmo
- Preguntar: "¬øEstos perfiles representan tipos de empleados que has visto en tu carrera?"
- Resultado esperado: Reconocimiento inmediato ("S√≠, el perfil 'Burnout' es exactamente lo que veo en el equipo de Ventas")

**2. Casos de estudio concretos:**
- Tomar 5 empleados de cada cluster y mostrar sus historias laborales completas
- Comparar con las predicciones del algoritmo
- Demostrar que el clustering captura patrones que los gerentes intu√≠an pero no pod√≠an cuantificar

**3. Piloto controlado:**
- Implementar primero en un departamento (ej: Accounting, 300 empleados)
- Medir rotaci√≥n antes y despu√©s de intervenciones basadas en clusters
- Mostrar reducci√≥n medible (ej: de 26% a 18% en 6 meses)

**4. Visualizaciones intuitivas:**
- Evitar jerga t√©cnica ("Silhouette", "centroides")
- Usar lenguaje empresarial ("Grupo de alto riesgo", "Perfil de estrella")
- Gr√°ficos simples: scatter plots 2D, tablas con caracter√≠sticas promedio

**5. Alineaci√≥n con conocimiento previo:**
- No contradecir intuiciones de los gerentes, sino complementarlas con datos
- Ejemplo: "Ustedes ya sab√≠an que HR tiene alta rotaci√≥n. Lo que el clustering agrega es que hay DOS perfiles dentro de HR: 'Burnout' (85% rotaci√≥n) y 'Nuevos' (40% rotaci√≥n), requiriendo estrategias distintas"

---

**P7: ¬øQu√© pasa si un empleado cambia de cluster con el tiempo?**

R: ¬°Exactamente! Esto es una feature, no un bug. La "migraci√≥n de clusters" es una se√±al de alerta temprana cr√≠tica:

**Migraciones "positivas" (√©xito de intervenci√≥n):**
- Onboarding ‚Üí Estrella: Onboarding exitoso, retener talento
- Estancado ‚Üí Onboarding: Re-engagement funcion√≥, seguir monitoreando
- Burnout ‚Üí Estrella: Recuperaci√≥n post-intervenci√≥n, caso de √©xito

**Migraciones "negativas" (alerta roja):**
- Estrella ‚Üí Burnout: **M√°xima prioridad**, intervenci√≥n inmediata antes de perder talento cr√≠tico
- Estrella ‚Üí Estancado: Se√±al de desvinculaci√≥n, revisar compensaci√≥n y carrera
- Onboarding ‚Üí Burnout: Fracaso de integraci√≥n, revisar carga y mentoreo

**Dashboard recomendado:**
```
ALERTAS DE MIGRACI√ìN DE CLUSTERS (√öltimos 30 d√≠as)

‚ö†Ô∏è CR√çTICO (5 empleados)
‚îú‚îÄ Empleado A: Estrella ‚Üí Burnout (Œî satisfaction: -0.4, Œî hours: +60/mes)
‚îî‚îÄ Empleado B: Estrella ‚Üí Burnout (Œî satisfaction: -0.5, Œî hours: +80/mes)

‚úÖ √âXITO (12 empleados)
‚îú‚îÄ Empleado C: Onboarding ‚Üí Estrella (Œî evaluation: +0.3, promoci√≥n reciente)
‚îî‚îÄ Empleado D: Estancado ‚Üí Onboarding (plan de mejora activo)
```

**Acci√≥n:** Re-ejecutar clustering mensualmente y trackear migraciones como KPI clave.

---

**P8: ¬øC√≥mo garantizan que el modelo no discrimine por departamento, sexo o edad?**

R: Esta es una preocupaci√≥n √©tica fundamental. Nuestra aproximaci√≥n es:

**1. Departamento NO es discriminaci√≥n prohibida:**
- Incluir departamento es legal y relevante (diferentes departamentos tienen din√°micas distintas)
- No estamos discriminando contra personas, sino segmentando equipos para intervenciones contextualizadas
- Ejemplo: Es leg√≠timo decir "HR tiene 29% de rotaci√≥n, requiere an√°lisis especial"

**2. Variables protegidas (sexo, edad, etnia) NO incluidas:**
- Verificamos que el dataset NO contiene variables protegidas por ley
- Si existieran, las excluir√≠amos del clustering
- Auditor√≠a peri√≥dica para confirmar no-discriminaci√≥n

**3. Validaci√≥n de fairness:**
- Calcular "disparate impact" por subgrupo (si tuvi√©ramos g√©nero): ¬øEl % de empleados en "Burnout" es similar entre hombres y mujeres?
- Si hay disparidad significativa (>80% vs <120%), revisar causas y ajustar features

**4. Transparencia algor√≠tmica:**
- K-means es auditable: los centroides muestran EXACTAMENTE por qu√© un empleado est√° en un cluster
- No es una "caja negra" como redes neuronales profundas
- Cualquier auditor puede verificar que las asignaciones son justas

**5. Uso √©tico de los resultados:**
- Los clusters se usan para MEJORAR condiciones (reducir sobrecarga, ofrecer capacitaci√≥n), NO para despedir
- Pol√≠ticas claras de uso: "Prohibido usar clustering para justificar despidos o reducir compensaci√≥n"

---

## ANEXO D: Material de Apoyo para la Presentaci√≥n

### Diapositivas Sugeridas (15 slides clave)

1. **T√≠tulo y Contexto**
   - T√≠tulo: "Clustering para Segmentaci√≥n de Empleados en Riesgo"
   - Subt√≠tulo: "An√°lisis No Supervisado Complementario a Clasificaci√≥n"
   - Logos: UNAB, Python, scikit-learn

2. **Objetivo del Trabajo**
   - Bullet points del objetivo
   - Gr√°fico de rotaci√≥n de personal (23.8% se fue)

3. **Diferencia: Supervisado vs No Supervisado**
   - Tabla comparativa (objetivo, input, output)
   - Diagrama visual: clasificaci√≥n (etiquetas) vs clustering (grupos naturales)

4. **Dataset y Preprocesamiento**
   - 14,999 empleados, 18 variables (7 num√©ricas + 11 transformadas de categ√≥ricas)
   - Pipeline: One-Hot Encoding ‚Üí StandardScaler ‚Üí K-means/Jer√°rquico

5. **M√©todo del Codo (K-means)**
   - Gr√°fico de inercia vs k
   - Indicaci√≥n del codo en k=4
   - M√©tricas complementarias: Silhouette=0.45, Davies-Bouldin=1.2

6. **Visualizaci√≥n 2D de Clusters (K-means)**
   - Scatter plot satisfaction_level vs average_montly_hours
   - 4 clusters coloreados con centroides marcados
   - Leyenda clara

7. **Centroides de los 4 Clusters**
   - Tabla con valores promedio de cada variable por cluster
   - Resaltar valores extremos (ej: Cluster 1 = 270 hrs/mes, Cluster 0 = 165 hrs/mes)

8. **Perfiles Empresariales**
   - 4 recuadros con caracterizaci√≥n:
     - Cluster 0: Estrella (25%, 5% rotaci√≥n)
     - Cluster 1: Burnout (15%, 85% rotaci√≥n) ‚ö†Ô∏è
     - Cluster 2: Estancado (30%, 70% rotaci√≥n)
     - Cluster 3: Onboarding (30%, 40% rotaci√≥n)

9. **Dendrograma (Clustering Jer√°rquico)**
   - Dendrograma con m√©todo Ward
   - L√≠nea de corte en k=4
   - Ramas coloreadas por cluster

10. **Comparaci√≥n K-means vs Jer√°rquico**
    - M√©tricas de concordancia: ARI=0.82, NMI=0.85
    - Conclusi√≥n: Ambos descubren estructuras similares ‚Üí Validaci√≥n robusta

11. **Validaci√≥n Externa: Clusters vs Rotaci√≥n**
    - Tabla de pureza por cluster (% de "se fue" en cada cluster)
    - Accuracy global: 80% como predictor
    - Comparaci√≥n con supervisado: 80% vs 94.8% (SVM RBF)

12. **Con PCA vs Sin PCA**
    - Tabla comparativa de m√©tricas (Silhouette, Davies-Bouldin, interpretabilidad)
    - Decisi√≥n: SIN PCA (priorizar interpretabilidad)

13. **Estrategia Empresarial por Cluster**
    - 4 estrategias espec√≠ficas con iconos:
      - Estrella: Desarrollo de liderazgo üåü
      - Burnout: Reducci√≥n de carga ‚ö†Ô∏è
      - Estancado: Reskilling üìö
      - Onboarding: Mentoreo ü§ù

14. **Impacto y ROI**
    - Gr√°fico de barras: Empleados retenidos por cluster (1,912 total)
    - ROI neto: $93.6M/a√±o (4,780% retorno)
    - Payback period: <1 mes

15. **Demo de Aplicaci√≥n Web + Cierre**
    - Screenshot de https://inferencia-estadistica-unab.streamlit.app/
    - URL visible y grande
    - Mensaje de cierre: "Clustering complementa clasificaci√≥n, no la reemplaza"

---

### Cronometraje Sugerido (Total: 18-20 minutos)

- **Introducci√≥n (3 min):** Objetivo, contexto, herramientas
- **Desarrollo Paso 1-3 (4 min):** Dataset, preprocesamiento, justificaci√≥n
- **Desarrollo Paso 4 (5 min):** K-means (codo, centroides, visualizaci√≥n)
- **Desarrollo Paso 5 (3 min):** Jer√°rquico (dendrograma, comparaci√≥n)
- **Desarrollo Paso 6-7 (2 min):** Validaci√≥n externa, PCA
- **Desarrollo Paso 8-9 (2 min):** Perfiles empresariales, implementaci√≥n web
- **Conclusi√≥n (3 min):** Resumen, t√©cnica √≥ptima, ROI
- **Preguntas (tiempo variable)**

---

### Tips de Presentaci√≥n Oral

**Lenguaje corporal:**
- Contacto visual distribuido (no fijarse solo en el docente)
- Gestos moderados para enfatizar n√∫meros clave (ej: "85% de rotaci√≥n en Burnout" ‚Üí gesto de alarma)
- Postura abierta y confiada

**√ânfasis vocal:**
- Pausar despu√©s de n√∫meros importantes: "94.8% de accuracy [pausa] versus 80% de clustering [pausa]"
- Variar tono al cambiar de secci√≥n (Introducci√≥n ‚Üí tono formal, Desarrollo ‚Üí tono explicativo, Conclusi√≥n ‚Üí tono entusiasta)
- Ralentizar en conceptos t√©cnicos (ej: "Coeficiente de Silhouette [lento] mide la cohesi√≥n interna de los clusters")

**Uso de diapositivas:**
- NO leer textualmente las slides
- Slides = apoyo visual, NO guion verbal
- Apuntar a elementos clave mientras se habla (ej: se√±alar el codo en el gr√°fico de inercia)

**Manejo de preguntas dif√≠ciles:**
- Escuchar completamente antes de responder
- Parafrasear la pregunta para confirmar comprensi√≥n: "Si entiendo bien, preguntas por qu√© elegimos k=4 en lugar de k=3..."
- Si no sabes la respuesta: "Excelente pregunta. En este an√°lisis no exploramos esa dimensi√≥n, pero ser√≠a una extensi√≥n valiosa para trabajo futuro"

---

**FIN DEL GUI√ìN PARA CLUSTERING**

**Versi√≥n:** 1.0  
**Fecha:** Noviembre 2025  
**Autor:** Equipo de An√°lisis de Datos - UNAB  
**Revisado por:** Prof. Inferencia Estad√≠stica y Reconocimiento de Patrones
