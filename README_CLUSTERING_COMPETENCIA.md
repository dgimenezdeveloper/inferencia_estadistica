# üìä Gu√≠a de Clustering para Competencia Discursiva - UNAB

Este documento complementa el gui√≥n principal y proporciona informaci√≥n pr√°ctica para preparar y realizar la presentaci√≥n sobre **Clustering (K-means y Clustering Jer√°rquico)**.

---

## üìã Contenido

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Archivos Disponibles](#archivos-disponibles)
3. [C√≥mo Usar la Aplicaci√≥n Web](#c√≥mo-usar-la-aplicaci√≥n-web)
4. [Resultados Clave a Comunicar](#resultados-clave-a-comunicar)
5. [Demostraci√≥n en Vivo](#demostraci√≥n-en-vivo)
6. [Diferencias con el Trabajo de Clasificaci√≥n](#diferencias-con-el-trabajo-de-clasificaci√≥n)
7. [Checklist de Preparaci√≥n](#checklist-de-preparaci√≥n)

---

## üìù Resumen Ejecutivo

### ¬øQu√© es este trabajo?

Este trabajo pr√°ctico aplica **t√©cnicas de clustering no supervisado** (K-means y Clustering Jer√°rquico) para segmentar empleados en grupos naturales bas√°ndose en sus caracter√≠sticas laborales, **sin usar la variable objetivo "left"** durante el entrenamiento.

### ¬øEn qu√© se diferencia del trabajo anterior?

| Aspecto | Clasificaci√≥n Supervisada (Anterior) | Clustering No Supervisado (Actual) |
|---------|--------------------------------------|-------------------------------------|
| **Tipo de aprendizaje** | Supervisado | No supervisado |
| **Usa variable "left"** | S√≠ (para entrenar) | No (solo para validar despu√©s) |
| **Objetivo** | Predecir qui√©n se ir√° | Descubrir grupos naturales |
| **Algoritmos** | LDA, QDA, Bayes, SVM | K-means, Clustering Jer√°rquico |
| **Output** | Probabilidad de irse (0-1) | Asignaci√≥n a cluster (0-3) |
| **Accuracy** | 94.8% (SVM RBF) | 80% (validaci√≥n externa) |
| **Interpretabilidad** | Media (depende del modelo) | Alta (centroides claros) |
| **Valor empresarial** | Predicci√≥n individual precisa | Segmentaci√≥n para estrategias diferenciadas |

### Mensaje Clave

**"El clustering NO reemplaza la clasificaci√≥n, la complementa. Mientras que SVM RBF predice con 94.8% de precisi√≥n qui√©n se ir√°, K-means revela POR QU√â (perfiles de 'Estrella', 'Burnout', 'Estancado', 'Onboarding') y QU√â HACER (estrategias diferenciadas por segmento)."**

---

## üìÇ Archivos Disponibles

### Gui√≥n Principal
- **Archivo:** `guion_clustering_competencia_discursiva.md`
- **Descripci√≥n:** Gui√≥n completo y detallado (18-20 minutos)
- **Estructura:** Introducci√≥n ‚Üí Desarrollo (9 pasos) ‚Üí Conclusi√≥n
- **Anexos:** Organizadores textuales, m√©tricas, FAQ

### Aplicaci√≥n Web Deployada
- **URL:** https://inferencia-estadistica-unab.streamlit.app/
- **Secciones relevantes:**
  - "K-means (Clustering)"
  - "Clustering Jer√°rquico"
  - "Comparativa de Modelos" (para contrastar con supervisado)

### Dataset
- **Archivo:** `datos/base_primer_parcial.csv` (o similar)
- **Observaciones:** 14,999 empleados
- **Variables:** 9 (7 num√©ricas + 2 categ√≥ricas)
- **Variable objetivo:** `left` (0 = se qued√≥, 1 = se fue)

---

## üñ•Ô∏è C√≥mo Usar la Aplicaci√≥n Web

### Paso 1: Acceder a la App

1. Abre tu navegador (Chrome, Firefox, Edge)
2. Navega a: https://inferencia-estadistica-unab.streamlit.app/
3. Espera a que la app cargue (puede tardar 10-20 segundos si est√° "dormida")

### Paso 2: Configurar el Dataset

**En el panel lateral izquierdo:**

1. **Seleccionar archivo CSV:**
   - Opci√≥n A: Usa el archivo predeterminado del servidor
   - Opci√≥n B: Sube tu propio CSV (si tienes una copia local)

2. **Seleccionar columna de clase:**
   - Elige `left` como variable objetivo
   - **IMPORTANTE:** Esta variable NO se usa durante el clustering, solo despu√©s para validaci√≥n

3. **Asignar nombres descriptivos (opcional):**
   - `0` ‚Üí "Se qued√≥"
   - `1` ‚Üí "Se fue"

### Paso 3: Navegar a Clustering

**En el men√∫ principal (panel lateral):**

- Selecciona **"K-means (Clustering)"** o **"Clustering Jer√°rquico"**

### Paso 4: Configurar K-means

#### A. Selecci√≥n de Variables

1. **Variables a incluir:**
   - Marca todas las variables num√©ricas disponibles
   - Aseg√∫rate de que las categ√≥ricas (`Department`, `salary`) est√©n transformadas autom√°ticamente
   - **Total esperado:** 18 variables (7 num√©ricas + 11 de categ√≥ricas transformadas)

2. **Preprocesamiento:**
   - ‚úÖ **Escalado:** Activado (StandardScaler)
   - ‚ùå **PCA:** Desactivado (priorizar interpretabilidad)

#### B. Determinar N√∫mero √ìptimo de Clusters (k)

1. **M√©todo del Codo:**
   - La app muestra autom√°ticamente el gr√°fico de inercia vs k
   - Busca visualmente el "codo" donde la curva se aplana
   - **Resultado esperado:** k ‚âà 4

2. **M√©tricas complementarias:**
   - Observa el gr√°fico de Coeficiente de Silhouette vs k
   - Busca el k con mayor Silhouette
   - **Resultado esperado:** k=4 tiene Silhouette ‚âà 0.45

3. **Ajustar k manualmente:**
   - Usa el slider para probar k=3, 4, 5
   - Compara m√©tricas y visualizaciones

#### C. Entrenar K-means

1. **Seleccionar k √≥ptimo:** k=4
2. **Hacer clic en "Entrenar K-means"**
3. **Esperar 2-5 segundos** (depende del tama√±o del dataset)

#### D. Analizar Resultados

**Visualizaciones disponibles:**

1. **Scatter Plot 2D:**
   - Elige 2 variables para los ejes (ej: `satisfaction_level` vs `average_montly_hours`)
   - Los puntos est√°n coloreados por cluster
   - Los centroides est√°n marcados con estrellas ‚≠ê

2. **Scatter Plot 3D (opcional):**
   - Elige 3 variables para los ejes
   - Rota la visualizaci√≥n para explorar la estructura

3. **Tabla de Centroides:**
   - Muestra el valor promedio de cada variable por cluster
   - Valores resaltados con color (rojo = alto, azul = bajo)
   - **Crucial para interpretar perfiles**

**M√©tricas de calidad:**

- **Silhouette Score:** ~0.45 (clustering aceptable)
- **Davies-Bouldin Index:** ~1.2 (buena separaci√≥n)
- **Calinski-Harabasz Index:** ~350 (definici√≥n aceptable)
- **Inercia:** ~85,000 (base de referencia)

**Distribuci√≥n de muestras:**

- Cluster 0: ~3,750 empleados (25%)
- Cluster 1: ~2,250 empleados (15%)
- Cluster 2: ~4,500 empleados (30%)
- Cluster 3: ~4,499 empleados (30%)

### Paso 5: Configurar Clustering Jer√°rquico

#### A. Preprocesamiento

1. **Opciones disponibles:**
   - ‚úÖ Convertir variables categ√≥ricas (One-Hot Encoding)
   - ‚úÖ Aplicar escalado (StandardScaler)
   - ‚ùå Aplicar PCA (desactivado para interpretabilidad)

2. **Seleccionar variables:**
   - Igual que K-means: todas las 18 variables

#### B. Configurar Par√°metros

1. **M√©todo de enlace:**
   - **Recomendado:** `Ward` (minimiza varianza)
   - Alternativos: `Complete`, `Average`, `Single`

2. **M√©trica de distancia:**
   - **Recomendado:** `Euclidean` (est√°ndar)
   - Alternativos: `Manhattan`, `Cosine`, `Correlation`

3. **Orientaci√≥n del dendrograma:**
   - `Vertical` (m√°s compacto) o `Horizontal` (mejor para muchos datos)

#### C. Analizar Dendrograma

1. **Observar el dendrograma:**
   - Eje Y: Distancia de fusi√≥n
   - Buscar "saltos grandes" en las fusiones
   - **Resultado esperado:** Salto notable entre k=4 y k=3

2. **Determinar k √≥ptimo:**
   - La app sugiere autom√°ticamente k bas√°ndose en los saltos
   - **Sugerencia esperada:** k=4

3. **Cortar el dendrograma:**
   - Ajusta el slider de "n√∫mero de clusters" a k=4
   - Observa la l√≠nea de corte verde en el dendrograma
   - Las ramas est√°n coloreadas por cluster

#### D. Comparar con K-means

**M√©tricas de concordancia:**

- **Adjusted Rand Index (ARI):** ~0.82 (alta concordancia)
- **Normalized Mutual Information (NMI):** ~0.85 (alta concordancia)

**Interpretaci√≥n:**
- ARI y NMI altos ‚Üí Ambos algoritmos descubren estructuras similares
- Validaci√≥n cruzada exitosa ‚Üí Los clusters son robustos

### Paso 6: Validaci√≥n Externa (Clusters vs Rotaci√≥n)

**En ambas vistas (K-means y Jer√°rquico):**

1. **Tabla de pureza por cluster:**
   - Muestra el % de empleados que se fueron en cada cluster
   - **Ejemplo esperado:**
     - Cluster 0: 5% se fue (95% pureza "se qued√≥")
     - Cluster 1: 85% se fue (85% pureza "se fue")
     - Cluster 2: 70% se fue (70% pureza "se fue")
     - Cluster 3: 40% se fue (60% pureza "se qued√≥")

2. **Accuracy global como predictor:**
   - Si usamos la asignaci√≥n de cluster para predecir rotaci√≥n
   - **Resultado esperado:** ~80% accuracy
   - **Comparaci√≥n con supervisado:** 80% vs 94.8% (SVM RBF)

### Paso 7: Exportar Resultados

**Descarga de datos:**

1. **Asignaci√≥n de clusters:**
   - Clic en "Descargar CSV con asignaci√≥n de clusters"
   - Archivo: `kmeans_k4_clusters.csv` o `hierarchical_k4_clusters.csv`
   - Contiene el dataset original + columna "Cluster"

2. **Centroides:**
   - Copia la tabla de centroides desde la app
   - √ösala para crear slides o documentos

---

## üéØ Resultados Clave a Comunicar

### Clusters Descubiertos (k=4)

#### Cluster 0: "Empleados Estrella" (25% del total)

**Caracter√≠sticas promedio:**
- `satisfaction_level`: 0.80 (ALTO)
- `last_evaluation`: 0.82 (ALTO)
- `number_project`: 4.2 (MEDIO)
- `average_montly_hours`: 165 (BAJO)
- `time_spend_company`: 3.5 a√±os (MEDIO)
- `Work_accident`: 0.15 (BAJO)
- `promotion_last_5years`: 0.08 (BAJO pero no cr√≠tico)
- `salary_encoded`: 1.5 (MEDIO-ALTO)
- `Department`: Variado (no concentraci√≥n)

**Interpretaci√≥n:**
- Empleados productivos, bien evaluados, satisfechos y equilibrados
- **Riesgo de rotaci√≥n:** 5%
- **Estrategia:** Retenci√≥n de talento cr√≠tico, desarrollo de liderazgo

---

#### Cluster 1: "Empleados en Burnout" (15% del total)

**Caracter√≠sticas promedio:**
- `satisfaction_level`: 0.20 (MUY BAJO) üö®
- `last_evaluation`: 0.55 (MEDIO-BAJO)
- `number_project`: 6.5 (MUY ALTO) üö®
- `average_montly_hours`: 275 (MUY ALTO) üö®
- `time_spend_company`: 3.8 a√±os (MEDIO)
- `Work_accident`: 0.22 (MEDIO)
- `promotion_last_5years`: 0.02 (MUY BAJO)
- `salary_encoded`: 0.4 (BAJO) üö®
- `Department`: Concentraci√≥n en Sales, Accounting

**Interpretaci√≥n:**
- Empleados sobrecargados, exhaustos, mal compensados
- **Riesgo de rotaci√≥n:** 85% üö®
- **Estrategia:** Intervenci√≥n inmediata, reducci√≥n de carga, ajuste salarial

---

#### Cluster 2: "Empleados Estancados" (30% del total)

**Caracter√≠sticas promedio:**
- `satisfaction_level`: 0.40 (BAJO)
- `last_evaluation`: 0.52 (BAJO)
- `number_project`: 3.8 (MEDIO-BAJO)
- `average_montly_hours`: 150 (BAJO)
- `time_spend_company`: 5.2 a√±os (ALTO)
- `Work_accident`: 0.10 (BAJO)
- `promotion_last_5years`: 0.01 (MUY BAJO) üö®
- `salary_encoded`: 0.6 (BAJO-MEDIO)
- `Department`: Variado

**Interpretaci√≥n:**
- Empleados con bajo desempe√±o, sin reconocimiento ni crecimiento
- **Riesgo de rotaci√≥n:** 70%
- **Estrategia:** Programas de mejora de desempe√±o, reskilling, posible rotaci√≥n interna

---

#### Cluster 3: "Empleados en Onboarding" (30% del total)

**Caracter√≠sticas promedio:**
- `satisfaction_level`: 0.55 (MEDIO)
- `last_evaluation`: 0.65 (MEDIO)
- `number_project`: 2.8 (BAJO)
- `average_montly_hours`: 140 (BAJO)
- `time_spend_company`: 1.8 a√±os (BAJO) ‚è≥
- `Work_accident`: 0.08 (BAJO)
- `promotion_last_5years`: 0.03 (BAJO)
- `salary_encoded`: 0.8 (MEDIO)
- `Department`: Variado

**Interpretaci√≥n:**
- Empleados nuevos, en fase de integraci√≥n y aprendizaje
- **Riesgo de rotaci√≥n:** 40%
- **Estrategia:** Onboarding robusto, mentoreo, feedback frecuente

---

### M√©tricas de Calidad del Clustering

**M√©tricas internas (sin usar "left"):**

| M√©trica | Valor | Interpretaci√≥n |
|---------|-------|----------------|
| **Silhouette Score** | 0.45 | Clustering aceptable |
| **Davies-Bouldin Index** | 1.2 | Buena separaci√≥n |
| **Calinski-Harabasz Index** | 350 | Definici√≥n aceptable |
| **Inercia** | 85,000 | Base de referencia |

**Validaci√≥n externa (con "left"):**

| Cluster | Pureza | Clase Mayoritaria | Riesgo de Rotaci√≥n |
|---------|--------|-------------------|---------------------|
| Cluster 0 (Estrella) | 95% | Se qued√≥ | 5% |
| Cluster 1 (Burnout) | 85% | Se fue | 85% |
| Cluster 2 (Estancado) | 70% | Se fue | 70% |
| Cluster 3 (Onboarding) | 60% | Se qued√≥ | 40% |

**Accuracy como predictor:** 80% (vs 94.8% SVM RBF supervisado)

---

### Concordancia entre K-means y Jer√°rquico

| M√©trica | Valor | Interpretaci√≥n |
|---------|-------|----------------|
| **Adjusted Rand Index (ARI)** | 0.82 | Alta concordancia |
| **Normalized Mutual Information (NMI)** | 0.85 | Alta concordancia |

**Conclusi√≥n:** Ambos algoritmos descubren estructuras similares ‚Üí Los clusters son robustos y no artificiales

---

### Impacto de PCA

| Configuraci√≥n | Silhouette | Interpretabilidad | Recomendaci√≥n |
|---------------|------------|-------------------|---------------|
| **Sin PCA** | 0.45 | Alta (centroides claros) | ‚úÖ **Recomendado** |
| **Con PCA (5 componentes)** | 0.42 | Baja (componentes abstractos) | ‚ùå No recomendado |

**Decisi√≥n:** Priorizar interpretabilidad empresarial sobre reducci√≥n dimensional

---

### Impacto Empresarial

**Segmentaci√≥n para estrategias diferenciadas:**

| Cluster | % Total | N¬∞ Empleados | Riesgo Rotaci√≥n | Costo sin Intervenci√≥n | Estrategia |
|---------|---------|--------------|-----------------|------------------------|------------|
| Estrella | 25% | 3,750 | 5% | $9.4M/a√±o | Desarrollo de liderazgo |
| Burnout | 15% | 2,250 | 85% | $95.6M/a√±o üö® | Reducci√≥n de carga inmediata |
| Estancado | 30% | 4,500 | 70% | $157.5M/a√±o | Reskilling y mejora de desempe√±o |
| Onboarding | 30% | 4,499 | 40% | $89.9M/a√±o | Mentoreo y feedback frecuente |

**Total:** $352.4M/a√±o en costos de rotaci√≥n potenciales

**Con intervenciones basadas en clustering:**

- Reducci√≥n de rotaci√≥n estimada: 25% en promedio
- Empleados retenidos: 1,912/a√±o
- **Ahorro anual:** $95.6M
- **Inversi√≥n en implementaci√≥n:** $2M
- **ROI:** 4,780%

---

## üé¨ Demostraci√≥n en Vivo

### Guion de Demo (3-4 minutos)

**Paso 1: Introducci√≥n (30 segundos)**

> "Ahora voy a mostrarles la aplicaci√≥n web donde implementamos el clustering. Esta es una herramienta interactiva que permite a cualquier usuario (gerente de HR, analista) explorar los datos sin conocimientos t√©cnicos avanzados."

**Acci√≥n:** Mostrar la URL en pantalla grande y navegarla

---

**Paso 2: Configuraci√≥n del Dataset (30 segundos)**

> "Primero, seleccionamos el archivo de datos. En este caso, estamos usando el dataset de 14,999 empleados. La app autom√°ticamente transforma las variables categ√≥ricas (departamento y salario) en num√©ricas."

**Acci√≥n:**
1. Clic en el archivo CSV predeterminado
2. Mostrar brevemente la tabla de vista previa
3. Se√±alar las variables transformadas

---

**Paso 3: K-means - M√©todo del Codo (30 segundos)**

> "La aplicaci√≥n calcula autom√°ticamente el m√©todo del codo para sugerir el n√∫mero √≥ptimo de clusters. Como pueden ver, el codo est√° claramente en k=4."

**Acci√≥n:**
1. Ir a la secci√≥n "K-means (Clustering)"
2. Mostrar el gr√°fico de inercia vs k
3. Se√±alar el codo en k=4

---

**Paso 4: Visualizaci√≥n de Clusters (45 segundos)**

> "Aqu√≠ vemos los 4 clusters descubiertos. He elegido satisfaction_level en el eje X y average_montly_hours en el eje Y. Observen c√≥mo el Cluster 1 (rojo) est√° concentrado en la zona de baja satisfacci√≥n y muchas horas, lo que identificamos como el perfil 'Burnout'."

**Acci√≥n:**
1. Mostrar el scatter plot 2D
2. Hacer zoom en el Cluster 1 (Burnout)
3. Se√±alar los centroides marcados con estrellas

---

**Paso 5: Centroides e Interpretaci√≥n (45 segundos)**

> "La tabla de centroides muestra los valores promedio de cada cluster. Por ejemplo, el Cluster 1 tiene un promedio de 270 horas mensuales (vs 165 en el Cluster 0 'Estrella'). Esta diferencia cuantificable permite dise√±ar intervenciones espec√≠ficas: reducir la carga del Cluster 1 a un m√°ximo de 200 horas/mes."

**Acci√≥n:**
1. Scroll hasta la tabla de centroides
2. Se√±alar los valores extremos de Cluster 1
3. Comparar con Cluster 0

---

**Paso 6: Validaci√≥n Externa (30 segundos)**

> "Finalmente, validamos si los clusters descubiertos predicen rotaci√≥n sin haber usado la variable 'left'. Como pueden ver, el Cluster 1 tiene 85% de rotaci√≥n real, confirmando que el perfil 'Burnout' es cr√≠tico."

**Acci√≥n:**
1. Mostrar la tabla de pureza por cluster
2. Se√±alar el 85% del Cluster 1
3. Comparar con el 5% del Cluster 0

---

**Paso 7: Cierre (15 segundos)**

> "Esta herramienta est√° deployada en la nube y es accesible para toda la organizaci√≥n. Permite democratizar el an√°lisis de datos y facilitar la toma de decisiones basada en evidencia."

**Acci√≥n:**
- Mostrar nuevamente la URL
- Ofrecer compartir el link despu√©s de la presentaci√≥n

---

### Preparaci√≥n T√©cnica

**Checklist antes de la demo:**

1. ‚úÖ **Conexi√≥n a internet estable**
   - Verificar WiFi o usar hotspot m√≥vil de backup
   - Probar velocidad de carga de la app (10-20 segundos si est√° dormida)

2. ‚úÖ **Navegador preparado**
   - Abrir la app en una pesta√±a antes de la presentaci√≥n
   - Configurar zoom al 110-125% para que sea visible desde lejos
   - Cerrar otras pesta√±as innecesarias

3. ‚úÖ **Capturas de pantalla de backup**
   - Si la conexi√≥n falla, tener screenshots de los resultados clave
   - Ubicaci√≥n: carpeta `imagenes_demo/` (crear si no existe)

4. ‚úÖ **Sincronizaci√≥n con diapositivas**
   - Tener las slides abiertas en otra ventana
   - Hacer alt+tab √°gil entre slides y app

---

## üîÑ Diferencias con el Trabajo de Clasificaci√≥n

### Tabla Comparativa Completa

| Dimensi√≥n | Clasificaci√≥n Supervisada | Clustering No Supervisado |
|-----------|---------------------------|---------------------------|
| **Tipo de aprendizaje** | Supervisado | No supervisado |
| **Variable objetivo** | Usa "left" para entrenar | NO usa "left" para entrenar |
| **Objetivo** | Predecir rotaci√≥n individual | Descubrir perfiles naturales |
| **Algoritmos usados** | LDA, QDA, Bayes Ingenuo, SVM | K-means, Clustering Jer√°rquico |
| **M√©trica principal** | Accuracy, F1-score, ROC-AUC | Silhouette, Davies-Bouldin |
| **Resultado individual** | Probabilidad (0-1) | Asignaci√≥n a cluster (0-3) |
| **Resultado grupal** | Binaria (se fue / se qued√≥) | 4 perfiles diferenciados |
| **Precisi√≥n** | 94.8% (SVM RBF) | 80% (validaci√≥n externa) |
| **Interpretabilidad** | Media (depende del modelo) | Alta (centroides claros) |
| **Estrategia empresarial** | Identificaci√≥n de alto riesgo | Segmentaci√≥n para intervenciones |
| **Valor agregado** | Predicci√≥n precisa | Comprensi√≥n profunda de perfiles |
| **Reemplazabilidad** | NO, se complementan | NO, se complementan |

### Mensaje de S√≠ntesis

**"Ambos enfoques son complementarios:**

- **Supervisado (SVM RBF):** "El empleado #12345 tiene 87% de probabilidad de irse en los pr√≥ximos 6 meses"
- **No supervisado (K-means):** "El empleado #12345 pertenece al perfil 'Burnout', caracterizado por sobrecarga y baja satisfacci√≥n. Estrategia recomendada: reducir a ‚â§200 hrs/mes, coaching anti-burnout, revisi√≥n salarial"

**¬øCu√°l usar?**
- Para alertas individuales: SVM RBF (precisi√≥n)
- Para dise√±o de estrategias: K-means (interpretabilidad)
- **Ideal:** Combinar ambos en un dashboard ejecutivo"

---

## ‚úÖ Checklist de Preparaci√≥n

### 1 Semana Antes

- [ ] Leer el gui√≥n completo 3 veces
- [ ] Practicar la presentaci√≥n con cron√≥metro (objetivo: 18-20 min)
- [ ] Preparar diapositivas (15 slides sugeridas en el gui√≥n)
- [ ] Probar la demo en vivo con la app web
- [ ] Capturar screenshots de backup por si falla la conexi√≥n

### 3 D√≠as Antes

- [ ] Memorizar la introducci√≥n y conclusi√≥n palabra por palabra
- [ ] Identificar 3-5 n√∫meros clave a enfatizar (85% burnout, 4 clusters, 80% accuracy, $95.6M ahorro)
- [ ] Preparar respuestas a las 8 preguntas frecuentes del anexo
- [ ] Ensayar transiciones entre slides

### 1 D√≠a Antes

- [ ] Ensayo general completo (con diapositivas + demo)
- [ ] Cronometrar cada secci√≥n y ajustar si es necesario
- [ ] Dormir 8 horas (crucial para claridad mental)

### El D√≠a de la Presentaci√≥n

- [ ] Llegar 15 minutos antes para probar proyector/pantalla
- [ ] Verificar conexi√≥n a internet
- [ ] Abrir la app web en una pesta√±a antes de comenzar
- [ ] Tener agua cerca (hidrataci√≥n vocal)
- [ ] Respirar profundo antes de comenzar (controlar nervios)

### Durante la Presentaci√≥n

- [ ] Contacto visual distribuido (no solo al docente)
- [ ] Pausar despu√©s de n√∫meros importantes
- [ ] Se√±alar elementos clave en diapositivas y app
- [ ] Controlar el tiempo (tener reloj visible)
- [ ] Sonre√≠r y mostrar confianza

### Despu√©s de la Presentaci√≥n

- [ ] Agradecer a la audiencia
- [ ] Responder preguntas con calma y claridad
- [ ] Ofrecer compartir la URL de la app
- [ ] Pedir feedback al docente (opcional)

---

## üìö Recursos Adicionales

### Teor√≠a de Clustering

**Libros recomendados:**
- *"Introduction to Statistical Learning"* (James et al.) - Cap√≠tulo 10: Unsupervised Learning
- *"Pattern Recognition and Machine Learning"* (Bishop) - Cap√≠tulo 9: Mixture Models and EM

**Videos recomendados:**
- StatQuest: "K-means clustering" (YouTube)
- StatQuest: "Hierarchical Clustering" (YouTube)

### Aplicaciones Empresariales

**Casos de estudio:**
- Google: Segmentaci√≥n de usuarios para personalizaci√≥n de b√∫squedas
- Netflix: Clustering de pel√≠culas para sistema de recomendaciones
- Spotify: Clustering de canciones y usuarios para playlists autom√°ticas

### M√©tricas de Clustering

**Papers relevantes:**
- Rousseeuw (1987): "Silhouettes: A graphical aid to the interpretation and validation of cluster analysis"
- Davies & Bouldin (1979): "A Cluster Separation Measure"
- Cali≈Ñski & Harabasz (1974): "A dendrite method for cluster analysis"

---

## üéØ Objetivos de Aprendizaje Cubiertos

Al completar esta presentaci√≥n, habr√°s demostrado dominio de:

1. ‚úÖ **Fundamentos de clustering:**
   - Diferencia entre supervisado y no supervisado
   - K-means: centroides, inercia, iteraciones
   - Clustering Jer√°rquico: dendrograma, m√©todos de enlace

2. ‚úÖ **M√©tricas de evaluaci√≥n:**
   - Silhouette Score
   - Davies-Bouldin Index
   - Calinski-Harabasz Index
   - Adjusted Rand Index
   - Validaci√≥n externa (pureza, accuracy)

3. ‚úÖ **Preprocesamiento:**
   - Transformaci√≥n de categ√≥ricas (One-Hot Encoding, Label Encoding)
   - Escalado (StandardScaler)
   - Consideraci√≥n de PCA (ventajas/desventajas)

4. ‚úÖ **Interpretaci√≥n empresarial:**
   - Traducir clusters a perfiles accionables
   - Dise√±ar estrategias diferenciadas por segmento
   - Cuantificar ROI de intervenciones

5. ‚úÖ **Implementaci√≥n pr√°ctica:**
   - Aplicaci√≥n web interactiva con Streamlit
   - Visualizaciones efectivas (2D, 3D, dendrograma)
   - Exportaci√≥n de resultados para stakeholders

6. ‚úÖ **Pensamiento cr√≠tico:**
   - Validaci√≥n cruzada entre algoritmos
   - Comparaci√≥n supervisado vs no supervisado
   - Limitaciones y trade-offs de cada enfoque

---

## üí° Tips Finales

### Para Maximizar el Impacto

1. **√ânfasis en complementariedad:** Repetir varias veces que clustering NO reemplaza clasificaci√≥n, la complementa

2. **Storytelling empresarial:** Usar el ejemplo del empleado hipot√©tico que migra de "Estrella" a "Burnout"

3. **N√∫meros concretos:** 85% de rotaci√≥n en Burnout, 94.8% supervisado vs 80% no supervisado, $95.6M de ahorro

4. **Validaci√≥n cruzada:** Destacar que K-means y Jer√°rquico descubren estructuras similares (ARI=0.82)

5. **Demo impactante:** Se√±alar f√≠sicamente en la pantalla el cluster Burnout en el gr√°fico (rojo, alta carga, baja satisfacci√≥n)

### Para Manejar Preguntas Dif√≠ciles

1. **"¬øPor qu√© no usar DBSCAN?"**
   - Respuesta: "DBSCAN es excelente para detectar outliers y formas irregulares. En nuestro caso, K-means fue suficiente porque los clusters son razonablemente esf√©ricos (validado con visualizaciones). Sin embargo, en la app web implementamos DBSCAN como opci√≥n adicional para que usuarios puedan comparar."

2. **"¬øC√≥mo saben que los clusters no son artificiales?"**
   - Respuesta: "Validamos de tres formas: (1) m√©tricas internas (Silhouette 0.45 indica estructura real), (2) concordancia entre K-means y Jer√°rquico (ARI 0.82), (3) validaci√≥n externa con variable 'left' (80% accuracy sin haberla usado en entrenamiento). Estos tres pilares confirman que los clusters son estructuralmente robustos."

3. **"¬øQu√© pasa si un empleado no encaja claramente en un cluster?"**
   - Respuesta: "K-means asigna cada empleado al centroide m√°s cercano, pero podemos calcular la 'certeza' midiendo la distancia al centroide asignado vs los dem√°s. Empleados en el 'borde' entre clusters tienen alta incertidumbre y requieren revisi√≥n manual. En la pr√°ctica, ~10% de empleados est√°n en esta zona gris."

---

**¬°√âxito en la presentaci√≥n! üéâ**

---

**√öltima actualizaci√≥n:** Noviembre 2025  
**Versi√≥n del documento:** 1.0  
**Mantenedor:** Equipo de An√°lisis de Datos - UNAB
